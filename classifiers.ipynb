{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vedikachauhan/Desktop/NLP_project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch \n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "device = th.device('cuda') if th.cuda.is_available() else th.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets (FOR NEW TRAINIGS FROM HERE)\n",
    "\n",
    "path=r\"Data_set/best_200songs_per20artist.csv\"\n",
    "#path=r\"C:/Users/JOSDA/Desktop/Autonomous systems/Second semester/NLP/Project/GIT/NLP_project/Data_set/best_100songs_per50artist_cleaned.csv\"\n",
    "\n",
    "#load the data\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Convert the embeddings from strings to lists\n",
    "data['embeddings'] = data['embeddings'].apply(ast.literal_eval)\n",
    "\n",
    "# Convert the labels from strings to lists\n",
    "embeddings = th.tensor(data['embeddings'].tolist())\n",
    "\n",
    "# Convert the labels from strings to lists   \n",
    "labels = th.tensor(data['labels'].tolist())\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(\n",
    "    embeddings, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Verificar la forma de los conjuntos\n",
    "print(\"Train embeddings shape:\", train_embeddings.shape)\n",
    "print(\"Test embeddings shape:\", test_embeddings.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist Classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE CLASSIFIER\n",
    "#MODELS\n",
    "\n",
    "# Classifier with one hidden layer, ReLU activation, and an output layer\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# IMPROVED CLASSIFIER \n",
    "# with two hidden layers, ReLU activation and dropout, and an output layer\n",
    "#dropout is used to prevent overfitting\n",
    "\n",
    "class ImprovedClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ImprovedClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  \n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.dropout1 = nn.Dropout(0.5)  \n",
    "        self.fc2 = nn.Linear(512, 256)  \n",
    "        self.relu2 = nn.ReLU() \n",
    "        self.dropout2 = nn.Dropout(0.5) \n",
    "        self.fc3 = nn.Linear(256, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  \n",
    "        x = self.relu1(x)  \n",
    "        x = self.dropout1(x)  \n",
    "        x = self.fc2(x)  # hidden layer\n",
    "        x = self.relu2(x)  \n",
    "        x = self.dropout2(x)  \n",
    "        x = self.fc3(x)  # output layer\n",
    "        return x\n",
    "\n",
    "# ENHANCED CLASSIFIER    \n",
    "# here we have added a third hidden layer to the model\n",
    "class EnhancedClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(EnhancedClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set the input size and number of classes\n",
    "input_size = train_embeddings.shape[1]  # size of the embeddings\n",
    "num_classes = len(set(labels.tolist()))  # number of unique labels(artist in our case)\n",
    "\n",
    "# Select the model to use\n",
    "#model = SimpleClassifier(input_size, num_classes).to(device)\n",
    "#model = ImprovedClassifier(input_size, num_classes).to(device)\n",
    "model = EnhancedClassifier(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "num_epochs = 350\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(train_embeddings.to(device))\n",
    "    loss = criterion(outputs, train_labels.to(device))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model and calculate the accuracy, confusion matrix and display it\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with th.no_grad():\n",
    "    test_outputs = model(test_embeddings.to(device))\n",
    "    _, predicted = th.max(test_outputs, 1)\n",
    "    correct = (predicted == test_labels.to(device)).sum().item()\n",
    "    accuracy = correct / test_labels.size(0)\n",
    "    print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "predicted = predicted.cpu().numpy()\n",
    "test_labels = test_labels.cpu().numpy()\n",
    "\n",
    "cm = confusion_matrix(test_labels, predicted)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=set(test_labels), yticklabels=set(test_labels))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restare the model if needed\n",
    "model = SimpleClassifier(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask and LSTM models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MULTITASK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTITASK MODER FOR GENRE AND ARTIST CLASSIFICATION(Josue)\n",
    "\n",
    "# Create a mapping of genres and artists to indices\n",
    "genre_to_index = {genre: idx for idx, genre in enumerate(data['tag'].unique())}\n",
    "artist_to_index = {artist: idx for idx, artist in enumerate(data['artist'].unique())}\n",
    "\n",
    "# Convert the genre and artist labels to tensors\n",
    "genre_labels = th.tensor([genre_to_index[genre] for genre in data['tag'].tolist()])\n",
    "artist_labels = th.tensor([artist_to_index[artist] for artist in data['artist'].tolist()])\n",
    "\n",
    "# Divide the data into training and testing sets\n",
    "train_embeddings, test_embeddings, train_genre_labels, test_genre_labels, train_artist_labels, test_artist_labels = train_test_split(\n",
    "    embeddings, genre_labels, artist_labels, test_size=0.2, random_state=42, stratify=artist_labels\n",
    ")\n",
    "\n",
    "# Define a multitask neural network for genre and artist classification the model has two output heads, one for genre and one for artist and \n",
    "# the model is trained to minimize the loss of both tasks simultaneously\n",
    "class MultitaskClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_genres, num_artists):\n",
    "        super(MultitaskClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.genre_head = nn.Linear(256, num_genres)\n",
    "        self.artist_head = nn.Linear(256, num_artists)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        genre_output = self.genre_head(x)\n",
    "        artist_output = self.artist_head(x)\n",
    "        return genre_output, artist_output\n",
    "\n",
    "# Model parameters\n",
    "input_size = train_embeddings.shape[1]\n",
    "num_genres = len(genre_to_index)\n",
    "num_artists = len(artist_to_index)\n",
    "\n",
    "model = MultitaskClassifier(input_size, num_genres, num_artists).to(device)\n",
    "\n",
    "# Define the loss functions and optimizer\n",
    "criterion_genre = nn.CrossEntropyLoss()\n",
    "criterion_artist = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n",
    "# Additional parameters to control the training process between the two tasks\n",
    "weight_genre_loss = 0.25  \n",
    "weight_artist_loss = 0.75  \n",
    "\n",
    "# Train the model\n",
    "num_epochs = 350\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    genre_outputs, artist_outputs = model(train_embeddings.to(device))\n",
    "    loss_genre = criterion_genre(genre_outputs, train_genre_labels.to(device))\n",
    "    loss_artist = criterion_artist(artist_outputs, train_artist_labels.to(device))\n",
    "    loss = weight_genre_loss * loss_genre + weight_artist_loss * loss_artist\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Genre Loss: {loss_genre.item():.4f}, Artist Loss: {loss_artist.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM MODEL (TANIA)\n",
    "\n",
    "path=r\"./Data_set/best_200songs_per20artist.csv\"\n",
    "\n",
    "#load the data\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# create genre and artist to index\n",
    "genre_to_index = {genre: idx for idx, genre in enumerate(data['tag'].unique())}\n",
    "artist_to_index = {artist: idx for idx, artist in enumerate(data['artist'].unique())}\n",
    "\n",
    "# convert to tensors\n",
    "genre_labels = torch.tensor([genre_to_index[genre] for genre in data['tag'].tolist()])\n",
    "artist_labels = torch.tensor([artist_to_index[artist] for artist in data['artist'].tolist()])\n",
    "\n",
    "data['embeddings'] = data['embeddings'].apply(ast.literal_eval)\n",
    "embeddings = torch.tensor(data['embeddings'].tolist())\n",
    "\n",
    "# split the dataset into train and test\n",
    "train_embeddings, test_embeddings, train_genre_labels, test_genre_labels, train_artist_labels, test_artist_labels = train_test_split(\n",
    "    embeddings, genre_labels, artist_labels, test_size=0.2, random_state=42, stratify=artist_labels\n",
    ")\n",
    "\n",
    "# Standardising embeddings\n",
    "scaler = StandardScaler()\n",
    "train_embeddings = torch.tensor(scaler.fit_transform(train_embeddings)).float()\n",
    "test_embeddings = torch.tensor(scaler.transform(test_embeddings)).float()\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_genres, num_artists):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.genre_fc = nn.Linear(hidden_size, num_genres)\n",
    "        self.artist_fc = nn.Linear(hidden_size, num_artists)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x.unsqueeze(1), (h0, c0)) \n",
    "        out = out[:, -1, :]  \n",
    "        \n",
    "        genre_out = self.genre_fc(out)\n",
    "        artist_out = self.artist_fc(out)\n",
    "        \n",
    "        return genre_out, artist_out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = train_embeddings.shape[1]  \n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_genres = len(genre_to_index)\n",
    "num_artists = len(artist_to_index)\n",
    "# create the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_genres, num_artists)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss and  optimezer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Train parameters\n",
    "num_epochs = 350\n",
    "\n",
    "# Train function\n",
    "def train_model(model, train_embeddings, train_genre_labels, train_artist_labels, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_embeddings = train_embeddings.to(device)\n",
    "        train_genre_labels = train_genre_labels.to(device)\n",
    "        train_artist_labels = train_artist_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        genre_outputs, artist_outputs = model(train_embeddings)\n",
    "        genre_loss = criterion(genre_outputs, train_genre_labels)\n",
    "        artist_loss = criterion(artist_outputs, train_artist_labels)\n",
    "        loss = genre_loss + artist_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "train_model(model, train_embeddings, train_genre_labels, train_artist_labels, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation and confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION AND CONFUSION MATRIX\n",
    "\n",
    "model.eval()\n",
    "with th.no_grad():\n",
    "    genre_outputs, artist_outputs = model(test_embeddings.to(device))\n",
    "    _, predicted_genres = th.max(genre_outputs, 1)\n",
    "    _, predicted_artists = th.max(artist_outputs, 1)\n",
    "    correct_genres = (predicted_genres == test_genre_labels.to(device)).sum().item()\n",
    "    correct_artists = (predicted_artists == test_artist_labels.to(device)).sum().item()\n",
    "    accuracy_genres = correct_genres / test_genre_labels.size(0)\n",
    "    accuracy_artists = correct_artists / test_artist_labels.size(0)\n",
    "    print(f'Accuracy on test set for genres: {accuracy_genres:.4f}')\n",
    "    print(f'Accuracy on test set for artists: {accuracy_artists:.4f}')\n",
    "\n",
    "# Convert the predictions and labels to numpy arrays\n",
    "predicted_genres = predicted_genres.cpu().numpy()\n",
    "test_genre_labels_np = test_genre_labels.cpu().numpy()\n",
    "predicted_artists = predicted_artists.cpu().numpy()\n",
    "test_artist_labels_np = test_artist_labels.cpu().numpy()\n",
    "\n",
    "# Confusion matrix for genres\n",
    "cm_genres = confusion_matrix(test_genre_labels_np, predicted_genres)\n",
    "\n",
    "# Confusion matrix for artists\n",
    "cm_artists = confusion_matrix(test_artist_labels_np, predicted_artists)\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "genre_labels_list = [label for label, _ in sorted(genre_to_index.items(), key=lambda item: item[1])]\n",
    "artist_labels_list = [label for label, _ in sorted(artist_to_index.items(), key=lambda item: item[1])]\n",
    "\n",
    "plot_confusion_matrix(cm_genres, genre_labels_list, 'Confusion Matrix for Genres')\n",
    "plot_confusion_matrix(cm_artists, artist_labels_list, 'Confusion Matrix for Artists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of artist and genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Song evaluation\n",
    "\n",
    "def predict_genre_and_artist(new_lyrics, model, scaler, genre_to_index, artist_to_index, device):\n",
    "    # tokenizer and BERT model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "    \n",
    "    # Tokenise the lyrics of the new song\n",
    "    tokens = tokenizer(new_lyrics, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = tokens['input_ids'].to(device)\n",
    "    \n",
    "    # embeddings of the new song\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids=input_ids)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings = embeddings.cpu()\n",
    "    \n",
    "    # Standardising embeddings\n",
    "    embeddings = torch.tensor(scaler.transform(embeddings)).float()\n",
    "    embeddings = embeddings.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # predicctions\n",
    "    with torch.no_grad():\n",
    "        genre_outputs, artist_outputs = model(embeddings)\n",
    "        genre_pred = torch.argmax(genre_outputs, dim=1)\n",
    "        artist_pred = torch.argmax(artist_outputs, dim=1)\n",
    "    \n",
    "    # Extract the artist and genre according to prediction\n",
    "    predicted_genre = [genre for genre, idx in genre_to_index.items() if idx == genre_pred.item()][0]\n",
    "    predicted_artist = [artist for artist, idx in artist_to_index.items() if idx == artist_pred.item()][0]\n",
    "    \n",
    "    return predicted_genre, predicted_artist\n",
    "\n",
    "\n",
    "new_lyrics = input(\"Enter the lyrics of the new song: \")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "predicted_genre, predicted_artist = predict_genre_and_artist(new_lyrics, model, scaler, genre_to_index, artist_to_index, device)\n",
    "print(f'The predicted genre is: {predicted_genre}')\n",
    "print(f'The predicted artist is: {predicted_artist}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lyrics Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from keras import optimizers as optimizers\n",
    "from keras import utils as np_utils\n",
    "from keras.api.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional, Embedding\n",
    "from keras.api.models import Sequential\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Device configuration for M1 chip\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                   title   tag              artist  year  \\\n",
      "3260                      Gimme Shelter  rock  The Rolling Stones  1969   \n",
      "3261          Cant You Hear Me Knocking  rock  The Rolling Stones  1971   \n",
      "3262  You Cant Always Get What You Want  rock  The Rolling Stones  1969   \n",
      "3263                    Beast of Burden  rock  The Rolling Stones  1978   \n",
      "3264                   Honky Tonk Women  rock  The Rolling Stones  1969   \n",
      "3265                      Tumbling Dice  rock  The Rolling Stones  1972   \n",
      "3266                              Bitch  rock  The Rolling Stones  1971   \n",
      "3267                     Paint It Black  rock  The Rolling Stones  1966   \n",
      "3268                     Under My Thumb  rock  The Rolling Stones  1966   \n",
      "3269             Sympathy for the Devil  rock  The Rolling Stones  1969   \n",
      "3270                        Start Me Up  rock  The Rolling Stones  1981   \n",
      "3271                              Angie  rock  The Rolling Stones  1973   \n",
      "3272                  Jumpin Jack Flash  rock  The Rolling Stones  1968   \n",
      "3273                       Dead Flowers  rock  The Rolling Stones  1971   \n",
      "3274                           Miss You  rock  The Rolling Stones  1978   \n",
      "3275                       Ruby Tuesday  rock  The Rolling Stones  1967   \n",
      "3276                        Brown Sugar  rock  The Rolling Stones  1971   \n",
      "3277         I Cant Get No Satisfaction  rock  The Rolling Stones  1965   \n",
      "3278                     Shes a Rainbow  rock  The Rolling Stones  1967   \n",
      "3279                        Wild Horses  rock  The Rolling Stones  1971   \n",
      "\n",
      "       views               features  \\\n",
      "3260  282692                     {}   \n",
      "3261   79237                     {}   \n",
      "3262  235294  {\"London Bach Choir\"}   \n",
      "3263  152108                     {}   \n",
      "3264   95951                     {}   \n",
      "3265   56264                     {}   \n",
      "3266   56581                     {}   \n",
      "3267  668886                     {}   \n",
      "3268   61725                     {}   \n",
      "3269  715037                     {}   \n",
      "3270   85190                     {}   \n",
      "3271  106124                     {}   \n",
      "3272   88540                     {}   \n",
      "3273   63739                     {}   \n",
      "3274  120350                     {}   \n",
      "3275   59143                     {}   \n",
      "3276  551643                     {}   \n",
      "3277  182266                     {}   \n",
      "3278  145645                     {}   \n",
      "3279  229150                     {}   \n",
      "\n",
      "                                                 lyrics      id language  \\\n",
      "3260  [Intro: Merry Clayton]\\nOoh\\nOoh\\nOoh\\n\\n[Vers...   73114       en   \n",
      "3261  [Part I]\\n\\n[Intro]\\n(Yeah)\\n\\n[Verse 1]\\nYeah...  105929       en   \n",
      "3262  [Intro: London Bach Choir]\\nI saw her today at...   81705       en   \n",
      "3263  [Intro]\\n\\n[Verse 1]\\nI'll never be your beast...  436889       en   \n",
      "3264  [Verse 1]\\nI met a gin-soaked barroom queen in...  194092       en   \n",
      "3265  [Intro]\\nMmm, yeah\\n\\n[Verse 1]\\nWomen think I...   77862       en   \n",
      "3266  [Verse 1]\\nI'm feeling so tired, can't underst...  106072       en   \n",
      "3267  [Verse 1]\\nI see a red door and I want it pain...    1545       en   \n",
      "3268  [Verse 1]\\nUnder my thumb\\nThe girl who once h...  172875       en   \n",
      "3269  [Instrumental Intro]\\nYow....yow....yow\\nHuh, ...   59472       en   \n",
      "3270  [Intro]\\nIf you start me up\\nIf you start me u...   49973       en   \n",
      "3271  [Verse 1]\\nAngie, Angie\\nWhen will those cloud...  140056       en   \n",
      "3272  [Instrumental Intro]\\n\\n[Intro]\\nOne two!\\n\\n[...  139411       en   \n",
      "3273  [Verse 1]\\nWell, when you're sitting there in ...  105931       en   \n",
      "3274  [Produced by The Glimmer Twins]\\n\\n[Verse 1]\\n...  133806       en   \n",
      "3275  [Verse 1]\\nShe would never say where she came ...  118293       en   \n",
      "3276  [Verse 1]\\nGold coast slave ship bound for cot...  106069       en   \n",
      "3277  [Instrumental Intro]\\n\\n[Chorus]\\nI can't get ...    1544       en   \n",
      "3278  [​Instrumental Intro]\\n\\n[Chorus]\\nShe comes i...  182062       en   \n",
      "3279  [Verse 1]\\nChildhood living is easy to do\\nThe...    1483       en   \n",
      "\n",
      "                                           clean_lyrics  \\\n",
      "3260  \\n Ooh \\n Ooh \\n Ooh \\n\\n\\n Ooh a storm is thr...   \n",
      "3261  \\n\\n\\n Yeah \\n\\n\\n Yeah you got satin shoes \\n...   \n",
      "3262  \\n I saw her today at the reception \\n A glass...   \n",
      "3263  \\n\\n\\n I 'll never be your beast of burden \\n ...   \n",
      "3264  \\n I met a gin soaked barroom queen in Memphis...   \n",
      "3265  \\n Mmm yeah \\n\\n\\n Women think I 'm tasty but ...   \n",
      "3266  \\n I 'm feeling so tired ca n't understand it ...   \n",
      "3267  \\n I see a red door and I want it painted blac...   \n",
      "3268  \\n Under my thumb \\n The girl who once had me ...   \n",
      "3269  \\n Yow yow yow \\n Huh huh huh \\n\\n\\n Please al...   \n",
      "3270  \\n If you start me up \\n If you start me up I ...   \n",
      "3271  \\n Angie Angie \\n When will those clouds all d...   \n",
      "3272  \\n\\n\\n One two \\n\\n\\n I was born in a crossfir...   \n",
      "3273  \\n Well when you 're sitting there in your sil...   \n",
      "3274  \\n\\n\\n I 've been holding out so long \\n I 've...   \n",
      "3275  \\n She would never say where she came from \\n ...   \n",
      "3276  \\n Gold coast slave ship bound for cotton fiel...   \n",
      "3277  \\n\\n\\n I ca n't get no satisfaction \\n I ca n'...   \n",
      "3278  \\n\\n\\n She comes in colours everywhere \\n She ...   \n",
      "3279  \\n Childhood living is easy to do \\n The thing...   \n",
      "\n",
      "                                  clean_lyrics_notspace  \\\n",
      "3260  Ooh Ooh Ooh Ooh a storm is threat'ning My very...   \n",
      "3261  Yeah Yeah you got satin shoes Yeah you got pla...   \n",
      "3262  I saw her today at the reception A glass of wi...   \n",
      "3263  I 'll never be your beast of burden My back is...   \n",
      "3264  I met a gin soaked barroom queen in Memphis Sh...   \n",
      "3265  Mmm yeah Women think I 'm tasty but they 're a...   \n",
      "3266  I 'm feeling so tired ca n't understand it Jus...   \n",
      "3267  I see a red door and I want it painted black N...   \n",
      "3268  Under my thumb The girl who once had me down U...   \n",
      "3269  Yow yow yow Huh huh huh Please allow me to int...   \n",
      "3270  If you start me up If you start me up I 'll ne...   \n",
      "3271  Angie Angie When will those clouds all disappe...   \n",
      "3272  One two I was born in a crossfire hurricane An...   \n",
      "3273  Well when you 're sitting there in your silk u...   \n",
      "3274  I 've been holding out so long I 've been slee...   \n",
      "3275  She would never say where she came from Yester...   \n",
      "3276  Gold coast slave ship bound for cotton fields ...   \n",
      "3277  I ca n't get no satisfaction I ca n't get no s...   \n",
      "3278  She comes in colours everywhere She combs her ...   \n",
      "3279  Childhood living is easy to do The things you ...   \n",
      "\n",
      "                                       tokenized_lyrics  \\\n",
      "3260  ['o', '##oh', 'o', '##oh', 'o', '##oh', 'o', '...   \n",
      "3261  ['yeah', 'yeah', 'you', 'got', 'satin', 'shoes...   \n",
      "3262  ['i', 'saw', 'her', 'today', 'at', 'the', 'rec...   \n",
      "3263  ['i', \"'\", 'll', 'never', 'be', 'your', 'beast...   \n",
      "3264  ['i', 'met', 'a', 'gin', 'soaked', 'barr', '##...   \n",
      "3265  ['mmm', 'yeah', 'women', 'think', 'i', \"'\", 'm...   \n",
      "3266  ['i', \"'\", 'm', 'feeling', 'so', 'tired', 'ca'...   \n",
      "3267  ['i', 'see', 'a', 'red', 'door', 'and', 'i', '...   \n",
      "3268  ['under', 'my', 'thumb', 'the', 'girl', 'who',...   \n",
      "3269  ['yo', '##w', 'yo', '##w', 'yo', '##w', 'huh',...   \n",
      "3270  ['if', 'you', 'start', 'me', 'up', 'if', 'you'...   \n",
      "3271  ['angie', 'angie', 'when', 'will', 'those', 'c...   \n",
      "3272  ['one', 'two', 'i', 'was', 'born', 'in', 'a', ...   \n",
      "3273  ['well', 'when', 'you', \"'\", 're', 'sitting', ...   \n",
      "3274  ['i', \"'\", 've', 'been', 'holding', 'out', 'so...   \n",
      "3275  ['she', 'would', 'never', 'say', 'where', 'she...   \n",
      "3276  ['gold', 'coast', 'slave', 'ship', 'bound', 'f...   \n",
      "3277  ['i', 'ca', 'n', \"'\", 't', 'get', 'no', 'satis...   \n",
      "3278  ['she', 'comes', 'in', 'colours', 'everywhere'...   \n",
      "3279  ['childhood', 'living', 'is', 'easy', 'to', 'd...   \n",
      "\n",
      "                                         encoded_inputs  \\\n",
      "3260  [101, 1051, 11631, 1051, 11631, 1051, 11631, 1...   \n",
      "3261  [101, 3398, 3398, 2017, 2288, 19412, 6007, 339...   \n",
      "3262  [101, 1045, 2387, 2014, 2651, 2012, 1996, 7684...   \n",
      "3263  [101, 1045, 1005, 2222, 2196, 2022, 2115, 6841...   \n",
      "3264  [101, 1045, 2777, 1037, 18353, 13077, 19820, 1...   \n",
      "3265  [101, 25391, 3398, 2308, 2228, 1045, 1005, 104...   \n",
      "3266  [101, 1045, 1005, 1049, 3110, 2061, 5458, 6187...   \n",
      "3267  [101, 1045, 2156, 1037, 2417, 2341, 1998, 1045...   \n",
      "3268  [101, 2104, 2026, 7639, 1996, 2611, 2040, 2320...   \n",
      "3269  [101, 10930, 2860, 10930, 2860, 10930, 2860, 9...   \n",
      "3270  [101, 2065, 2017, 2707, 2033, 2039, 2065, 2017...   \n",
      "3271  [101, 14835, 14835, 2043, 2097, 2216, 8044, 20...   \n",
      "3272  [101, 2028, 2048, 1045, 2001, 2141, 1999, 1037...   \n",
      "3273  [101, 2092, 2043, 2017, 1005, 2128, 3564, 2045...   \n",
      "3274  [101, 1045, 1005, 2310, 2042, 3173, 2041, 2061...   \n",
      "3275  [101, 2016, 2052, 2196, 2360, 2073, 2016, 2234...   \n",
      "3276  [101, 2751, 3023, 6658, 2911, 5391, 2005, 6557...   \n",
      "3277  [101, 1045, 6187, 1050, 1005, 1056, 2131, 2053...   \n",
      "3278  [101, 2016, 3310, 1999, 8604, 7249, 2016, 2286...   \n",
      "3279  [101, 5593, 2542, 2003, 3733, 2000, 2079, 1996...   \n",
      "\n",
      "                                             embeddings  labels  \n",
      "3260  [-0.7897894978523254, -0.06742453575134277, 0....      54  \n",
      "3261  [-0.3793235123157501, 0.20059561729431152, 0.0...      54  \n",
      "3262  [-0.806023120880127, -0.0006926984060555696, 0...      54  \n",
      "3263  [-0.024700604379177094, 0.07370158284902573, -...      54  \n",
      "3264  [-0.15812209248542786, 0.07556508481502533, -0...      54  \n",
      "3265  [-0.6301671862602234, 0.04400075227022171, 0.0...      54  \n",
      "3266  [-0.22348245978355408, -0.1197047084569931, -0...      54  \n",
      "3267  [0.01586003601551056, -0.2675597369670868, 0.3...      54  \n",
      "3268  [-0.3065488338470459, -0.05388554558157921, -0...      54  \n",
      "3269  [-0.5186355113983154, 0.08259683102369308, -0....      54  \n",
      "3270  [-0.7789493203163147, 0.06988634914159775, 0.2...      54  \n",
      "3271  [-0.6028704047203064, 0.41057923436164856, 0.3...      54  \n",
      "3272  [-0.5557006597518921, 0.2966506779193878, -0.3...      54  \n",
      "3273  [-0.7031199932098389, -0.05083189532160759, -0...      54  \n",
      "3274  [0.1214728131890297, 0.09373902529478073, 0.10...      54  \n",
      "3275  [-0.1785004436969757, -0.15455001592636108, -0...      54  \n",
      "3276  [-0.4966241121292114, -0.01623772270977497, 0....      54  \n",
      "3277  [-0.6217943429946899, -0.08981237560510635, 0....      54  \n",
      "3278  [-0.751529335975647, -0.08381616324186325, 0.2...      54  \n",
      "3279  [-0.05459527298808098, 0.006823737174272537, -...      54  >\n",
      "Size of Dataset: (20, 15)\n",
      "Number of unique characters: 958\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "data = pd.read_csv(\"Data_set/best_20songs_perartist.csv\")\n",
    "\n",
    "#Filter the data for a specific artist\n",
    "artist_name = \"The Rolling Stones\"\n",
    "data = data[data['artist'] == artist_name]\n",
    "\n",
    "#Display the dataset\n",
    "print(data.head)\n",
    "\n",
    "#Display the size of the dataset\n",
    "print(\"Size of Dataset:\", data.shape)\n",
    "\n",
    "#Combining all lyrics to create a corpus\n",
    "corpus = []\n",
    "for lyrics in data['clean_lyrics']:\n",
    "    lyrics = re.sub(r'[^a-zA-Z0-9\\s]', '', str(lyrics))\n",
    "    corpus.extend(lyrics.split())\n",
    "\n",
    "#Display number of unique characters in the corpus\n",
    "print(\"Number of unique characters:\", len(set(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared. Features shape: (5255, 40) Targets shape: (5255, 958)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 372ms/step - accuracy: 0.0192 - loss: 6.7199 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.0325 - loss: 6.0366 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.0304 - loss: 5.8388 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 388ms/step - accuracy: 0.0414 - loss: 5.7026 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 421ms/step - accuracy: 0.0385 - loss: 5.7771 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.0383 - loss: 5.7649 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.0447 - loss: 5.7156 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 450ms/step - accuracy: 0.0417 - loss: 5.5787 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 463ms/step - accuracy: 0.0408 - loss: 5.5095 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 464ms/step - accuracy: 0.0485 - loss: 5.4464 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 457ms/step - accuracy: 0.0567 - loss: 5.3138 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 458ms/step - accuracy: 0.0620 - loss: 5.3547 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 459ms/step - accuracy: 0.0661 - loss: 5.2653 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.0725 - loss: 5.2072 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 465ms/step - accuracy: 0.0829 - loss: 5.1252 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 461ms/step - accuracy: 0.0865 - loss: 4.9589 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 460ms/step - accuracy: 0.0903 - loss: 4.9333 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 460ms/step - accuracy: 0.0986 - loss: 4.8629 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 461ms/step - accuracy: 0.1143 - loss: 4.7205 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 466ms/step - accuracy: 0.1143 - loss: 4.6639 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.1288 - loss: 4.6217 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.1423 - loss: 4.4730 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - accuracy: 0.1249 - loss: 4.4894 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 456ms/step - accuracy: 0.1498 - loss: 4.3564 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 461ms/step - accuracy: 0.1811 - loss: 4.1998 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 460ms/step - accuracy: 0.1537 - loss: 4.2939 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 457ms/step - accuracy: 0.1678 - loss: 4.2810 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.1617 - loss: 4.2628 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.1765 - loss: 4.1690 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 464ms/step - accuracy: 0.1894 - loss: 4.1460 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.1742 - loss: 4.1202 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 459ms/step - accuracy: 0.1971 - loss: 3.9744 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 465ms/step - accuracy: 0.1804 - loss: 4.0417 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.1877 - loss: 4.0415 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.1774 - loss: 4.0618 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.1797 - loss: 4.0737 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 465ms/step - accuracy: 0.1947 - loss: 3.9360 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.1962 - loss: 3.9506 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.2115 - loss: 3.9087 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 471ms/step - accuracy: 0.2201 - loss: 3.8240 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 471ms/step - accuracy: 0.2391 - loss: 3.8054 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 475ms/step - accuracy: 0.2500 - loss: 3.7005 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 486ms/step - accuracy: 0.2657 - loss: 3.5933 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.2770 - loss: 3.5023 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 475ms/step - accuracy: 0.2830 - loss: 3.4744 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.2809 - loss: 3.4201 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.2703 - loss: 3.5201 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 470ms/step - accuracy: 0.2639 - loss: 3.5076 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.2670 - loss: 3.5157 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - accuracy: 0.2821 - loss: 3.4014 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 471ms/step - accuracy: 0.2716 - loss: 3.4173 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.2846 - loss: 3.3919 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.2966 - loss: 3.2779 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.2768 - loss: 3.3257 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 481ms/step - accuracy: 0.2736 - loss: 3.3449 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 471ms/step - accuracy: 0.2767 - loss: 3.3730 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.2622 - loss: 3.3957 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.2881 - loss: 3.2676 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.2945 - loss: 3.2785 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.2971 - loss: 3.2688 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.3139 - loss: 3.1732 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.3220 - loss: 3.1507 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 466ms/step - accuracy: 0.3395 - loss: 3.0560 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.3705 - loss: 2.9336 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 477ms/step - accuracy: 0.3756 - loss: 2.8600 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.3945 - loss: 2.7905 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.3978 - loss: 2.7666 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3719 - loss: 2.8667 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.3681 - loss: 2.8600 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3593 - loss: 2.9080 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.3787 - loss: 2.8032 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 470ms/step - accuracy: 0.3681 - loss: 2.8126 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3659 - loss: 2.8346 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.3863 - loss: 2.7114 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.3745 - loss: 2.7447 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3884 - loss: 2.7410 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3724 - loss: 2.7924 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.3620 - loss: 2.8192 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3928 - loss: 2.6925 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.3881 - loss: 2.7099 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.3906 - loss: 2.7274 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.4056 - loss: 2.6328 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.4100 - loss: 2.6326 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.4173 - loss: 2.5522 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 486ms/step - accuracy: 0.4500 - loss: 2.4386 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 478ms/step - accuracy: 0.4579 - loss: 2.3968 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 465ms/step - accuracy: 0.4708 - loss: 2.3241 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.4677 - loss: 2.3298 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 465ms/step - accuracy: 0.4599 - loss: 2.3997 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 470ms/step - accuracy: 0.4636 - loss: 2.3909 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.4494 - loss: 2.4369 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.4616 - loss: 2.3506 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.4540 - loss: 2.3885 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.4344 - loss: 2.3747 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 466ms/step - accuracy: 0.4620 - loss: 2.2978 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.4527 - loss: 2.3332 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.4668 - loss: 2.3224 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.4405 - loss: 2.3785 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.4327 - loss: 2.4364 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.4664 - loss: 2.2904 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.4597 - loss: 2.3301 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.4639 - loss: 2.2923 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - accuracy: 0.4841 - loss: 2.2149 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.4828 - loss: 2.2127 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.5019 - loss: 2.1376 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.5294 - loss: 2.0224 - learning_rate: 0.0010\n",
      "Epoch 107/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.5494 - loss: 1.9579 - learning_rate: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - accuracy: 0.5444 - loss: 1.9344 - learning_rate: 0.0010\n",
      "Epoch 109/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 471ms/step - accuracy: 0.5469 - loss: 1.9091 - learning_rate: 0.0010\n",
      "Epoch 110/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.5426 - loss: 1.9555 - learning_rate: 0.0010\n",
      "Epoch 111/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.5395 - loss: 1.9653 - learning_rate: 0.0010\n",
      "Epoch 112/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.5354 - loss: 1.9843 - learning_rate: 0.0010\n",
      "Epoch 113/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.5614 - loss: 1.9100 - learning_rate: 0.0010\n",
      "Epoch 114/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.5491 - loss: 1.9248 - learning_rate: 0.0010\n",
      "Epoch 115/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 470ms/step - accuracy: 0.5394 - loss: 1.9595 - learning_rate: 0.0010\n",
      "Epoch 116/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.5537 - loss: 1.8545 - learning_rate: 0.0010\n",
      "Epoch 117/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.5609 - loss: 1.8775 - learning_rate: 0.0010\n",
      "Epoch 118/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.5616 - loss: 1.8823 - learning_rate: 0.0010\n",
      "Epoch 119/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.5423 - loss: 1.9285 - learning_rate: 0.0010\n",
      "Epoch 120/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.5418 - loss: 1.9485 - learning_rate: 0.0010\n",
      "Epoch 121/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.5483 - loss: 1.8749 - learning_rate: 0.0010\n",
      "Epoch 122/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.5507 - loss: 1.9005 - learning_rate: 0.0010\n",
      "Epoch 123/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.5541 - loss: 1.9205 - learning_rate: 0.0010\n",
      "Epoch 124/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.5620 - loss: 1.8503 - learning_rate: 0.0010\n",
      "Epoch 125/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 469ms/step - accuracy: 0.5505 - loss: 1.8763 - learning_rate: 0.0010\n",
      "Epoch 126/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.5536 - loss: 1.8070 - learning_rate: 0.0010\n",
      "Epoch 127/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.5999 - loss: 1.6989 - learning_rate: 0.0010\n",
      "Epoch 128/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 475ms/step - accuracy: 0.6168 - loss: 1.6215 - learning_rate: 0.0010\n",
      "Epoch 129/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.6310 - loss: 1.5958 - learning_rate: 0.0010\n",
      "Epoch 130/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.6190 - loss: 1.5887 - learning_rate: 0.0010\n",
      "Epoch 131/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.6137 - loss: 1.6442 - learning_rate: 0.0010\n",
      "Epoch 132/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.6168 - loss: 1.6481 - learning_rate: 0.0010\n",
      "Epoch 133/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.6075 - loss: 1.6677 - learning_rate: 0.0010\n",
      "Epoch 134/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.6274 - loss: 1.5839 - learning_rate: 0.0010\n",
      "Epoch 135/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - accuracy: 0.6134 - loss: 1.6045 - learning_rate: 0.0010\n",
      "Epoch 136/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.6117 - loss: 1.6163 - learning_rate: 0.0010\n",
      "Epoch 137/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.6242 - loss: 1.5719 - learning_rate: 0.0010\n",
      "Epoch 138/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.6199 - loss: 1.5784 - learning_rate: 0.0010\n",
      "Epoch 139/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.6278 - loss: 1.5751 - learning_rate: 0.0010\n",
      "Epoch 140/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 487ms/step - accuracy: 0.6154 - loss: 1.6161 - learning_rate: 0.0010\n",
      "Epoch 141/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.6025 - loss: 1.6546 - learning_rate: 0.0010\n",
      "Epoch 142/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.6285 - loss: 1.5370 - learning_rate: 0.0010\n",
      "Epoch 143/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.6150 - loss: 1.5862 - learning_rate: 0.0010\n",
      "Epoch 144/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.6194 - loss: 1.6070 - learning_rate: 0.0010\n",
      "Epoch 145/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 484ms/step - accuracy: 0.6113 - loss: 1.5626 - learning_rate: 0.0010\n",
      "Epoch 146/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 484ms/step - accuracy: 0.6133 - loss: 1.5693 - learning_rate: 0.0010\n",
      "Epoch 147/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.6172 - loss: 1.5298 - learning_rate: 0.0010\n",
      "Epoch 148/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.6503 - loss: 1.4477 - learning_rate: 0.0010\n",
      "Epoch 149/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 483ms/step - accuracy: 0.6605 - loss: 1.3763 - learning_rate: 0.0010\n",
      "Epoch 150/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.6815 - loss: 1.3332 - learning_rate: 0.0010\n",
      "Epoch 151/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.6796 - loss: 1.3204 - learning_rate: 0.0010\n",
      "Epoch 152/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.6694 - loss: 1.3672 - learning_rate: 0.0010\n",
      "Epoch 153/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 471ms/step - accuracy: 0.6605 - loss: 1.3997 - learning_rate: 0.0010\n",
      "Epoch 154/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.6579 - loss: 1.4051 - learning_rate: 0.0010\n",
      "Epoch 155/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - accuracy: 0.6721 - loss: 1.3695 - learning_rate: 0.0010\n",
      "Epoch 156/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.6749 - loss: 1.3338 - learning_rate: 0.0010\n",
      "Epoch 157/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.6667 - loss: 1.3732 - learning_rate: 0.0010\n",
      "Epoch 158/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.6803 - loss: 1.3231 - learning_rate: 0.0010\n",
      "Epoch 159/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.6701 - loss: 1.3484 - learning_rate: 0.0010\n",
      "Epoch 160/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.6898 - loss: 1.3076 - learning_rate: 0.0010\n",
      "Epoch 161/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - accuracy: 0.6775 - loss: 1.3570 - learning_rate: 0.0010\n",
      "Epoch 162/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.6423 - loss: 1.4270 - learning_rate: 0.0010\n",
      "Epoch 163/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.6651 - loss: 1.3314 - learning_rate: 0.0010\n",
      "Epoch 164/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.6700 - loss: 1.3619 - learning_rate: 0.0010\n",
      "Epoch 165/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.6620 - loss: 1.3812 - learning_rate: 0.0010\n",
      "Epoch 166/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.6704 - loss: 1.3254 - learning_rate: 0.0010\n",
      "Epoch 167/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.6584 - loss: 1.3724 - learning_rate: 0.0010\n",
      "Epoch 168/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - accuracy: 0.6588 - loss: 1.3492 - learning_rate: 0.0010\n",
      "Epoch 169/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.6986 - loss: 1.2322 - learning_rate: 0.0010\n",
      "Epoch 170/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.7133 - loss: 1.1731 - learning_rate: 0.0010\n",
      "Epoch 171/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.7215 - loss: 1.1445 - learning_rate: 0.0010\n",
      "Epoch 172/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.7221 - loss: 1.1153 - learning_rate: 0.0010\n",
      "Epoch 173/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - accuracy: 0.7072 - loss: 1.2056 - learning_rate: 0.0010\n",
      "Epoch 174/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.7073 - loss: 1.2096 - learning_rate: 0.0010\n",
      "Epoch 175/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - accuracy: 0.7009 - loss: 1.2094 - learning_rate: 0.0010\n",
      "Epoch 176/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.7249 - loss: 1.1550 - learning_rate: 0.0010\n",
      "Epoch 177/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.7192 - loss: 1.1599 - learning_rate: 0.0010\n",
      "Epoch 178/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 493ms/step - accuracy: 0.7062 - loss: 1.2006 - learning_rate: 0.0010\n",
      "Epoch 179/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.7029 - loss: 1.1755 - learning_rate: 0.0010\n",
      "Epoch 180/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.6966 - loss: 1.1907 - learning_rate: 0.0010\n",
      "Epoch 181/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.7165 - loss: 1.1525 - learning_rate: 0.0010\n",
      "Epoch 182/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - accuracy: 0.6959 - loss: 1.1870 - learning_rate: 0.0010\n",
      "Epoch 183/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.6853 - loss: 1.2671 - learning_rate: 0.0010\n",
      "Epoch 184/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.7035 - loss: 1.1687 - learning_rate: 0.0010\n",
      "Epoch 185/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.6888 - loss: 1.2108 - learning_rate: 0.0010\n",
      "Epoch 186/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 481ms/step - accuracy: 0.7026 - loss: 1.2140 - learning_rate: 0.0010\n",
      "Epoch 187/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.6979 - loss: 1.1649 - learning_rate: 0.0010\n",
      "Epoch 188/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 487ms/step - accuracy: 0.6907 - loss: 1.1791 - learning_rate: 0.0010\n",
      "Epoch 189/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.7113 - loss: 1.1388 - learning_rate: 0.0010\n",
      "Epoch 190/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - accuracy: 0.7315 - loss: 1.0759 - learning_rate: 0.0010\n",
      "Epoch 191/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 494ms/step - accuracy: 0.7477 - loss: 1.0057 - learning_rate: 0.0010\n",
      "Epoch 192/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.7516 - loss: 1.0012 - learning_rate: 0.0010\n",
      "Epoch 193/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 479ms/step - accuracy: 0.7643 - loss: 0.9524 - learning_rate: 0.0010\n",
      "Epoch 194/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 495ms/step - accuracy: 0.7594 - loss: 1.0100 - learning_rate: 0.0010\n",
      "Epoch 195/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 483ms/step - accuracy: 0.7439 - loss: 1.0191 - learning_rate: 0.0010\n",
      "Epoch 196/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 492ms/step - accuracy: 0.7407 - loss: 1.0427 - learning_rate: 0.0010\n",
      "Epoch 197/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - accuracy: 0.7688 - loss: 0.9615 - learning_rate: 0.0010\n",
      "Epoch 198/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.7557 - loss: 0.9898 - learning_rate: 0.0010\n",
      "Epoch 199/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - accuracy: 0.7395 - loss: 1.0220 - learning_rate: 0.0010\n",
      "Epoch 200/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 496ms/step - accuracy: 0.7567 - loss: 0.9719 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#Building dictionaries for mapping characters to indices and vice versa\n",
    "unique_chars = sorted(set(corpus))\n",
    "mapping = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "reverse_mapping = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "#Prepare sequences for training\n",
    "length = 40\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(0, len(corpus) - length, 1):\n",
    "    feature = corpus[i:i + length]\n",
    "    target = corpus[i + length]\n",
    "    features.append([mapping[char] for char in feature])\n",
    "    targets.append(mapping[target])\n",
    "\n",
    "#Converting to numpy arrays for better performance\n",
    "features = np.array(features, dtype=np.int32)\n",
    "targets = np.array(targets, dtype=np.int32)\n",
    "\n",
    "#One-hot encode the output variable\n",
    "y = np_utils.to_categorical(targets, num_classes=len(unique_chars))\n",
    "\n",
    "print(\"Data prepared. Features shape:\", features.shape, \"Targets shape:\", y.shape)\n",
    "\n",
    "#Define the model\n",
    "embedding_dim = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(unique_chars), embedding_dim, input_length=length))  # Add embedding layer\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(unique_chars), activation='softmax'))\n",
    "\n",
    "#Compile the model with accuracy metric\n",
    "opt = optimizers.Adam(learning_rate=0.001) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "#Train\n",
    "def data_generator(features, targets, batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(features), batch_size):\n",
    "            end = min(start + batch_size, len(features))\n",
    "            yield features[start:end], targets[start:end]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "steps_per_epoch = len(features) // batch_size\n",
    "\n",
    "history = model.fit(data_generator(features, y, batch_size),\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[reduce_lr])\n",
    "\n",
    "model.save('lyrics_generator.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.title(\"Learning Plot of Model for Loss and Accuracy\")\n",
    "plt.plot(history_df[\"loss\"], color=\"#444160\", label=\"Loss\")\n",
    "plt.plot(history_df[\"accuracy\"], color=\"#ff5733\", label=\"Accuracy\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig('learning_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ooh Ooh Ooh Ooh a storm is threatning My very life today If I do nt get some shelter Ooh yeah I m gon na fade away War children It s just a shot away it s just a shot today tears long long Oh craps upholstered ship craps today Baby fate Rican saints who can slave Cadillac hands today fate Cadillac can tears can long women English pain Jack today hot tears stained Flash pink tears Rican Baby upholstered Alright can Anastasia waiting girl flavor today pink tears very upholstered pink saints tears tears tears long tears Anastasia Making flavor can saints English Baby fire Pleased Pleased can saints today Under today saints heart saints brown upholstered hands can saints Come can As English tears Cadillac very English Flash Oh runs saints Oh can Cadillac pain No in after very stank yow information yow Oh hands English gas can saints Oh long upholstered upholstered saints can saints upholstered saints Well Making today life hands life can today Oh saints tears coal English hands today Tuesday long Under Anastasia shooter long today stank Cadillac exits yeah Cadillac Oh hands can English hands taste baby today Making Flash waiting long hot hot long can Alright long can pink very upholstered singing Cadillac As long tears drugstore life Pleased upholstered Pretty pink As Pleased upholstered very Cadillac very long long who broken today today then bound upholstered can saints hot today very upholstered Huh hands Come English today is Alright lines queen bound saints tears moment hands tears boulevards very today life long hands Music English long can Gimme tears very mean life waiting ship upholstered Oh baby upholstered house hands upholstered moment flavor Music cold yeah my flavor Who tears courtesy upholstered can huh Come I tears today Cadillac pink moment Music slave can very Oh Come tears Under Oh very craps can always saints queen pink pink today shooter life street Cadillac tears craps To Oh cold long very tears can Rican craps moment Oh after queen my waiting craps street Cadillac Music I waiting Music hands English today can tears Cadillac today today And Roll tears today his can mean long long bodies I today craps long hands hands Making Making today upholstered can Making hands Baby upholstered bound upholstered Cadillac upholstered today long tears saints Cadillac can Cadillac upholstered English waiting flavor Cadillac saints my carpet Oh moment fate can very can English Cadillac today tears Music Cadillac hot saints upholstered tears long Flash long Making upholstered Cadillac pink flavor bound just Jack ship Cadillac upholstered upholstered upholstered screamed long long now waiting tears then after Music upholstered\n"
     ]
    }
   ],
   "source": [
    "#Generate lyrics\n",
    "def lyrics_generator(model, starter, length, temperature=1.0):\n",
    "    generated = starter\n",
    "    seed = [mapping[char] for char in starter.split()]\n",
    "    for _ in range(length):\n",
    "        x_pred = np.reshape(seed, (1, len(seed))) / float(len(unique_chars))\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        predictions = np.asarray(predictions).astype('float64')\n",
    "        predictions = np.log(predictions) / temperature\n",
    "        exp_preds = np.exp(predictions)\n",
    "        predictions = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, predictions, 1)\n",
    "        next_index = np.argmax(probas)\n",
    "        next_char = reverse_mapping[next_index]\n",
    "        generated += ' ' + next_char\n",
    "        seed = seed[1:] + [next_index]\n",
    "    return generated\n",
    "\n",
    "starter_sequence = \" \".join(corpus[:length])\n",
    "song = lyrics_generator(model, starter_sequence, 400)\n",
    "print(song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
